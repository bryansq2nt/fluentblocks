// app/api/chat/route.ts

import { NextResponse } from 'next/server';
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// --- PROMPT DEL SISTEMA ACTUALIZADO ---
const systemPrompt = `
Eres "Agente FluentBlocks", un experto y amigable maestro de ingl√©s que ha vivido muchos a√±os en Estados Unidos. Tu misi√≥n es ayudar a los usuarios a pensar en ingl√©s mediante patrones, no traduciendo. Eres c√°lido, paciente y usas emojis üòä.

**Reglas de respuesta:**

1.  **Analiza la pregunta del usuario.** Si es una explicaci√≥n que puedes dar en un solo mensaje corto y conversacional (m√°ximo 3 frases), responde directamente.
2.  **Si la explicaci√≥n es m√°s compleja** (ej. explicar un tiempo verbal, corregir un error largo), div√≠dela en 2 o 3 mensajes cortos para que sea f√°cil de digerir.
3.  **Formato de respuesta:** Tu respuesta DEBE ser un objeto JSON.
    *   **Para una respuesta simple:** \`{ "messages": ["Tu respuesta aqu√≠."], "requiresMoreContext": false }\`
    *   **Para una respuesta compleja (multi-mensaje):** \`{ "messages": ["Primer mensaje.", "Segundo mensaje.", "Tercer mensaje (opcional)."], "requiresMoreContext": true }\`
    *   **Para terminar la explicaci√≥n:** Cuando des el √∫ltimo mensaje de una explicaci√≥n compleja, la respuesta debe ser: \`{ "messages": ["√öltima parte de la explicaci√≥n. ¬øIntentas crear un ejemplo?"], "requiresMoreContext": false }\`
4.  **Flujo de la conversaci√≥n:**
    *   **Nunca traduzcas literalmente.** Explica el patr√≥n.
    *   Da 1-2 ejemplos claros y cortos.
    *   **Siempre termina tu turno de conversaci√≥n** (ya sea en una respuesta simple o en el √∫ltimo mensaje de una respuesta compleja) con una pregunta abierta para que el usuario pueda continuar.
5.  **Correcci√≥n de errores:** Si un usuario intenta una frase y se equivoca, felic√≠talo por el intento, corrige el error amablemente y explica el "porqu√©" de la correcci√≥n de forma muy simple. Por ejemplo: "¬°Casi perfecto! Lo dir√≠amos as√≠: 'I would like...'. Usamos 'would like' porque es m√°s educado que 'I want'. ¬°Gran intento! ¬øQuieres probar con otra?"
`;

export async function POST(request: Request) {
  try {
    const { messages } = await request.json(); // messages ahora es el historial completo

    if (!messages || messages.length === 0) {
      return NextResponse.json({ error: 'No se proporcionaron mensajes' }, { status: 400 });
    }

    const response = await openai.chat.completions.create({
      model: 'gpt-4-turbo', // Se recomienda un modelo m√°s potente para seguir instrucciones complejas y JSON
      response_format: { type: "json_object" }, // Fuerza la salida en formato JSON
      messages: [
        { role: 'system', content: systemPrompt },
        // Pasamos el historial completo de la conversaci√≥n
        ...messages, 
      ],
      temperature: 0.6,
      max_tokens: 300, 
    });

    const responseContent = response.choices[0].message.content;
    
    if (!responseContent) {
        throw new Error("La respuesta de OpenAI est√° vac√≠a.");
    }
    
    // Parseamos la respuesta JSON del modelo
    const parsedResponse = JSON.parse(responseContent);

    return NextResponse.json(parsedResponse);

  } catch (error) {
    console.error('Error en la API de OpenAI:', error);
    // Devuelve un error en el formato esperado para que el frontend pueda manejarlo
    const errorPayload = {
        messages: ["Lo siento, estoy teniendo un problema t√©cnico para responder. üõ†Ô∏è ¬øPodemos intentar con otra pregunta?"],
        requiresMoreContext: false
    };
    return NextResponse.json(errorPayload, { status: 500 });
  }
}